_cvat_credentials: &cvat_credentials
  host: "http://localhost:8080/api/v1"
  credentials: dev_cvat

# Cotton counting dataset from CVAT containing full images
# with point annotations.
cotton_images:
  type: pycvat.CvatDataSet
  task_id: 2
  << : *cvat_credentials

# Cotton counting datasets from CVAT containing image patches with
# image-level annotations.
cotton_patches_1:
  type: pycvat.CvatDataSet
  task_id: 111
  << : *cvat_credentials

# Cotton counting dataset annotations, stored locally.
local_annotations:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/annotations/annotations.parquet
  versioned: True

# TFRecord dataset of training split.
tfrecord_train:
  type: cotton_counter.data_sets.TfRecordsDataSet
  filepath: data/05_model_input/train.tfrecord
  versioned: True

# TFRecord dataset of testing split.
tfrecord_test:
  type: cotton_counter.data_sets.TfRecordsDataSet
  filepath: data/05_model_input/test.tfrecord
  versioned: True

# TFRecord dataset of validation split.
tfrecord_validate:
  type: cotton_counter.data_sets.TfRecordsDataSet
  filepath: data/05_model_input/validate.tfrecord
  versioned: True

# TFRecord dataset of tag-annotated patches. It's split
# into separate datasets for negative and positive examples,
# to make class balancing easy.
tfrecord_tagged_patches_positive:
  type: cotton_counter.data_sets.TfRecordsDataSet
  filepath: data/05_model_input/positive_patches.tfrecord
  versioned: True

tfrecord_tagged_patches_negative:
  type: cotton_counter.data_sets.TfRecordsDataSet
  filepath: data/05_model_input/negative_patches.tfrecord
  versioned: True

# Intermediate TF Datasets containing pre-processed data.
training_data:
  type: MemoryDataSet
  copy_mode: assign

testing_data:
  type: MemoryDataSet
  copy_mode: assign

validation_data:
  type: MemoryDataSet
  copy_mode: assign

tagged_patch_data_positive:
  type: MemoryDataSet
  copy_mode: assign

tagged_patch_data_negative:
  type: MemoryDataSet
  copy_mode: assign

# Intermediate TF Dataset containing patches with tag annotations.
# It is sourced from both the training point dataset and the tagged
# patch dataset.
combined_training_data:
  type: MemoryDataSet
  copy_mode: assign

# A dataset containing validation data but with no patches extracted.
validation_data_no_patches:
  type: MemoryDataSet
  copy_mode: assign

_model_args: &model_args
  type: tensorflow.TensorFlowModelDataset
  load_args:
    # Compiling during loading doesn't work with custom loss functions.
    compile: False
  save_args:
    save_format: h5
  versioned: True

# Saved model, produced at the end of training.
trained_model:
  filepath: ${output_data_dir}/06_models/fully_trained.hd5
  << : *model_args
