# Batch size to use for inference.
prediction_batch_size: 64
